---
title: "MS1 clustering"
output:
  html_notebook: default
---

Clustering MS data requires some quality control that can be done in R.

In addition, we will need to use a `bash` script that calls multiple Python scripts. 
All scripts are available in `bin/`. 
This notebook explains how the data from the manuscript was clustered.

First, let's load all required R libraries:

```{r, message=F, error=F}
library(renv) #remotes::install_github("rstudio/renv")
renv::restore()
library(tidyverse)
library(stringr)
library(DESeq2)
library(data.table)
library(dendextend)
library(here)
library(impute)
library(pvclust)
library(gplots)
library(RColorBrewer)
library(cluster)
library(cutr) #devtools::install_github("moodymudskipper/cutr")
#renv::snapshot()
```



## Data input and normalization

Let's input our MS1 feature intensity file and our metadata file that has information on the microbiome treatments. The MS1 features and corresponding intensities were identified using OpenMS. 

*Note: The OpemMS output files were subset to only include the intensity values due to file size limitations*

```{r}                                                                                                                                                                                                   

intensity <- read.csv(here::here("data", "ms1", "ms1_intensity.csv"), row.names=1)
metadata <- read.csv(here::here("data", "meta_data.csv")) %>%
    mutate(plate_cell = paste0("P2", Cell))
int_col <- colnames(intensity) %>% data.frame(.)
metadata <- left_join(int_col, metadata, by=c("." = "plate_cell")) ## only including
meta_drug <- metadata %>% arrange(., Drug)
intensity <- intensity %>% dplyr::select(meta_drug$.)
colnames(intensity) <- meta_drug$Name
```

We want to filter the data by missing values and low intensity values. MS1 data is inherently noisy, and so we also filter by low intensity. In this case, we identify intensity quartiles and consider the lowest quartile missing values **only** for the 


```{r}
cond_options_x <- table(metadata$Drug) %>% as.data.frame()

## options for drug specific filtering
## want to change intensities below a noise threshold for 
cond_opts <- cond_options_x$Var1
cond_count <- cond_options_x$Freq * 0.5

int <- intensity %>% pivot_longer(names_to = "Name", values_to="intensity", cols=everything()) %>% drop_na()
head(int)
summary(int$intensity)
int_4_quartiles <- smart_cut(int$intensity,4,"groups", labels = c("remove", "Low", "Med", "High"))
table(int_4_quartiles)
int$quart <- int_4_quartiles
max_to_remove <- int %>% filter(quart == "remove")
max_to_remove <- max_to_remove$intensity %>% max()

dens <- density(log2(int$intensity))
df <- data.frame(x=dens$x, y=dens$y)
probs <- c(0,0.25,0.5,0.75,1)
quantiles <- quantile(log2(int$intensity), prob=probs)
df$quant <- factor(findInterval(df$x,quantiles))


(pep_quart_plot <- ggplot(df, aes(x,y)) + geom_line() + 
    geom_ribbon(aes(ymin=0, ymax=y, fill=quant)) + 
    scale_x_continuous(breaks=quantiles) + 
    #scale_fill_brewer(guide="none") +
    xlab("MS1 feature intensities") +
    ylab("Density") +
    scale_fill_viridis_d(option = "plasma", guide = "none") +
    theme_bw() +
    theme(text=element_text(size=14)) 
)

#ggsave(here::here("figs", "ms1quart.pdf"), pep_quart_plot, width = 10, height = 6, units = "in")

is.nan.data.frame <- function(x){
    do.call(cbind, lapply(x, is.nan))}

filter_valids_quart = function(df, conditions, min_count, int_remove, at_least_one = TRUE) {
    df[is.nan.data.frame(df)] <- 0
    df[is.na(df)] <- 0
    df[df <= int_remove] <- 0
    all_names <- colnames(df) 
    cond.names = lapply(conditions, # Group column names by conditions
                        function(x) grep(x, all_names, value = TRUE, perl = TRUE))
    cond.filter = sapply(1:length(cond.names), function(i) {
        df2 = df %>% dplyr::select(cond.names[[i]])   # Extract columns of interest
        df2 = as.matrix(df2)   # Cast as matrix for the following command
        sums = rowSums(df2!=0) # count the number of valid values for each condition
        sums >= min_count[i]   # Calculates whether min_count requirement is met
    })
    if (at_least_one) {
        df$KEEP = apply(cond.filter, 1, any)
    } else {
        df$KEEP = apply(cond.filter, 1, all)
    }
    return(df)  # only keeping rows that meet the criteria!
}

## filter by at least Q50 in each treatment considering ZEROS and anything in low quartile
drug_exp_filt_quart <- filter_valids_quart(intensity, 
                               conditions = cond_opts,
                               min_count = cond_count, 
                               int_remove = max_to_remove,
                               at_least_one = T) 
drug_exp_filt_quart <- intensity[drug_exp_filt_quart$KEEP == 1,] ## 37,484
## Normalize by library size
norm_pep <- estimateSizeFactorsForMatrix(drug_exp_filt_quart)
norm_exp <- sweep(drug_exp_filt_quart, 2, norm_pep, "/") ##peptides are normalized
```

## Missing data imputation

Although we filtered data, we are still left with missing values that will cause challenges with log transformation and fold change calculations. We used a KNN data imputation.

```{r, message=F, warning=F}
## impute missing values
norm_exp[norm_exp== 0] <- NA
imputed_pep<- impute.knn(norm_exp %>% as.matrix(), k = 10, rowmax = 0.5, colmax = 0.95, rng.seed = 362436069)
```

## Log2 intensity transformation and PCA quality check

We then should log transform the intensity values and perform a PCA for a QC check.

```{r, message=F, warning=F}
log_exp <- data.frame(imputed_pep$data) %>%
    mutate_all(., funs(log2(1 + .)))
colnames(log_exp) = colnames(imputed_pep$data)
pca<- prcomp(log_exp %>% t(), center=T, scale=F)
sampleVals<-data.frame(pca$x)
exprVals<-data.frame(pca$rotation)
PoV <- (pca$sdev^2/sum(pca$sdev^2))*100 

coords<-data.frame(sampleVals, Drug = meta_drug$Drug,
                   samplename = rownames(sampleVals),
                   Concentration = meta_drug$Conc)
coords$Concentration <- factor(coords$Concentration, levels = c("H", "M", "L", "1D"))
numPCs <- 1:length(PoV)

for (i in 1:length(PoV)) {
    percent <- paste0("(", round(PoV[i],2), "%)")
    name <- paste0("PC", i, "per")
    assign(name, percent)
}

## easy and quick PCA function for manual colour and shape
quick_pca <- function(coords_df, x_PC, y_PC, shape, fill){
    yaxis <- y_PC
    xaxis <- x_PC
    yperc <- paste0("(", round(PoV[yaxis %>% as.numeric()] ,2), "%)")
    xperc <- paste0("(", round(PoV[xaxis %>% as.numeric()] ,2), "%)")
    
    yaxislabel <- paste0("PC", yaxis, " ", yperc)
    xaxislabel <- paste0("PC", xaxis, " ", xperc)
    pca_plot <- ggplot(coords, aes_string(x = paste0('PC', xaxis), y = paste0('PC', yaxis))) +
        geom_point(size=4, aes_string(shape = shape, color = fill)) + 
        scale_color_manual(values=c("#3444DA",  "#DF737A", "#8C5999", "#00916E", "#D7C0D0", "#FFBA49")) +
        scale_x_continuous(name=xaxislabel) + 
        scale_y_continuous(name=yaxislabel) +
        theme_bw() +
        theme(legend.position = "right", text=element_text(size=16))
    return(pca_plot)
}
(pc12 <- quick_pca(coords_df = coords, x_PC = 2, y_PC = 1, shape = "Concentration", fill = "Drug"))

(pc23 <- quick_pca(coords_df = coords, x_PC = 2, y_PC = 3, shape = "Concentration", fill = "Drug"))
```

## Calculating log2 fold change 

We are using [precise-db's](https://github.com/SBRG/precise-db) implementation of robust components in ICA matrix decomposition. This implementation required fold change values. 

We need to write this log2 FC to a file because the ICA implementation is written in Python. 

```{r}
ctrl <- dplyr::select(log_exp, contains("NC"))
ctrl$median = apply(ctrl, 1, median, na.rm = T)
drug_temp <- dplyr::select(log_exp, -contains("NC"))
ctrl<- matrix(ctrl$median, nrow=length(ctrl$median), ncol=ncol(drug_temp), byrow=F)

fc <- ctrl - drug_temp

noctrlmeta <- meta_drug  %>% filter(Drug != "NC") 
fc <- fc %>% dplyr::select(noctrlmeta$Name)
#write.csv(fc, here::here("data","ms1", "ms1_fc.csv"), quote=F, row.names = T)
```



## Clustering

Clustering can be completed the following scripts provided in `bin/`. The ICA implementation of precise-db requires a conda environment which can be accessed using `conda activate precise-db`.

Once ICA has completed it's run, you will find `S.csv` (and other relevent files) in your chosen output directory. We will be clustering this matrix using `kmed_clustering.py` This script was written considering the newest versions of used packages, thus, `kmed_clustering.py` also has it's own `conda` environment named `k-med`. 

The following should be run in your terminal and requires `conda` and `python`.

```{zsh engine.opts='-i', eval=F}
## THIS IS A SHELL SCRIPT
## It is best to run this in it's own terminal window because of RStudio's memory limitations 
cd ./bin
# You will need to create a specific conda environment for ICA. 
# Uncomment the code below to create the environment
# conda env create -f environment.yml
conda activate precise-db
## script for robust ICA matrix decomposition
## Update -n to as many threads you have available; ideally at least 6 
## However this will run on a laptop with fewer cores, it just may take longer 
sh run_ica.sh -i 100 -t 1e-8 -n 6 -o ../../data/msms/ -l ../../data/msms/ica.log ../../data/msms/ms2_fc.csv
conda deactivate 

# to create the correct conda environment for clustering
#conda env create -f k-med_env.yml
# This k-medoid clustering relies on newer modules than the ica implementation 
conda activate k-med 
./kmed_clutering.py -s ../data/msms/S.csv -d ../data/msms/
conda deactivate 

```

## Cluster eigenfeature calculation and clustering visualization

After we use `Python` for clustering our relatively large dataset, let's calculate summary statistics of each peptide cluster considering the peptide intensity values. We will calculate eigenfactors two ways and compare the two results.


```{r message=F, warning=F}
kmedoid_labels <- read.csv(here::here("data", "ms1", "k-med_labels.csv"), header=F) %>% as.vector()

clusterinfopep <- kmedoid_labels %>% data.frame()

max_clust <- kmedoid_labels %>% unique() %>% max()
print(paste("Number of clusters:", max_clust))
fc_clusters <- list()

## creating a list that contains intensities of each peptide cluster
for (x in 0:max_clust){
    clustername <- paste("Cluster", x)
    y <- kmedoid_labels[which(kmedoid_labels$V1 == x),,drop=F] %>% rownames()
    fc_clusters[[clustername]] <- fc[y %>% as.numeric(),]
    fc_clusters[[clustername]]$feat_num <- y 
}

### eigenfactors
### Singular value decomposition for genome-wide expression data processing and modeling
###  https://doi.org/10.1073/pnas.97.18.10101
## https://www.biostars.org/p/299167/
## eigengenes <- svd(X)$v
## We are using PCA
pca_clusters <- lapply(fc_clusters, function(x) prcomp(x %>% dplyr::select(-feat_num) %>% t(), center=T, scale=F)$x)
svd_clusters <- lapply(fc_clusters, function(x) svd(x %>% dplyr::select(-feat_num))$v)
# grabbing the first principal component
svd1_cluster <- lapply(svd_clusters,  "[", , 1)
pc1_cluster <- lapply(pca_clusters,  "[", , 1)
clustereigenfactors_pca <- bind_cols(pc1_cluster) %>% data.frame()
clustereigenfactors_svd <- bind_cols(svd1_cluster) %>% data.frame()
```

After calculating eigenfactors for each peptide cluster, we correlate each eigenfactor to each sample's drug treatment.

```{r message=F, warning=F}
## make a factored dataframe of the compounds
noctrlmeta <- noctrlmeta %>% mutate(drug_conc = paste0(Drug, "-", Conc))

datTraits <- data.frame(compounds= as.factor(noctrlmeta$drug_conc))
rownames(datTraits) <- noctrlmeta$Name
traits <- model.matrix(~ ., data=datTraits,
                       contrasts.arg = lapply(datTraits, contrasts, contrasts=FALSE))
traits <- traits[,-1] ##removing intercept
moduleTraitCor_pca <- stats::cor(clustereigenfactors_pca, traits, method = "s")
moduleTraitCor_svd <- stats::cor(clustereigenfactors_svd, traits, method = "s")
colnames(moduleTraitCor_pca) <- colnames(moduleTraitCor_pca) %>% substr(., 10, nchar(colnames(moduleTraitCor_pca)))
colnames(moduleTraitCor_svd) <- colnames(moduleTraitCor_svd) %>% substr(., 10, nchar(colnames(moduleTraitCor_svd)))
```

We cluster drug treatments using correlation distance. To identify robust clusters, we perform 1000 bootstrap iterations. Let's look at *PCA-derived* eigenfeature clusters first.

```{r, message=F, warning = F}
module_clust_pca <- hclust(as.dist(1-cor(t(moduleTraitCor_pca), method="pearson")), method="average")
drug_clust_pca <- hclust(as.dist(1-cor(moduleTraitCor_pca, method="pearson")), method="average")
drug_clust_boot_pca <- pvclust(moduleTraitCor_pca, method.hclust="average",
                           method.dist="correlation", nboot=1000,
                           iseed=2248)

## Visualize the bootstrap clusters
clust_boot_pca <- as.dendrogram(drug_clust_boot_pca)
drug_clust_boot_pca %>% as.dendrogram() %>% plot(main = "MS1-PCA")
drug_clust_boot_pca %>% text 
drug_clust_boot_pca %>% pvrect(alpha=0.9, pv="au")


# colours for heatmap
new_palette <- colorRampPalette(c("#70A9A1", "white", "#FF9633"))(n=120)

## metadata for clustr heatmap
cor_meta_pca <- data.frame(treatment = colnames(moduleTraitCor_pca)) %>%
    mutate(drug_col = case_when(str_detect(treatment, 'AZ') ~ '#3444DA',
                                str_detect(treatment, 'CP') ~ '#DF737A',
                                str_detect(treatment, 'DC') ~ '#8C5999',
                                str_detect(treatment, 'NZ') ~ '#D7C0D0',
                                str_detect(treatment, 'PR') ~ '#FFBA49'
                                )) %>%
    mutate(conc_col = case_when(str_detect(treatment, '-H') ~ '#08090A',
                                str_detect(treatment, '-M') ~ '#96999C',
                                str_detect(treatment, '-L') ~ '#EAEBEB'))
range(moduleTraitCor_pca)
## Uncomment to save PDF of heatmap
#pdf(here::here("figs", "ms1_kmed_hm_pca.pdf"), width=9, height=6)
par(xpd = TRUE) # allows legend to be outside "official" plotting lines
coords2 <- list(x=0, y=0.95)
heatmap.2(moduleTraitCor_pca,
          notecol="black",      # change font color of cell labels to black
          density.info="none",  # turns off density plot inside color legend
          trace="none",         # turns off trace lines inside the heat map
          margins =c(5,0),      # widens margins around plot
          col=new_palette,      # 
          breaks=seq(-0.6,0.6,0.01),    # enable color transition at specified limits
          dendrogram="col",     # only draw a row dendrogram
          Colv=as.dendrogram(drug_clust_pca),            # turn off column clustering
          Rowv=as.dendrogram(module_clust_pca),
          #ColSideColors = cor_meta$drug_col,
          ColSideColors = cor_meta_pca$drug_col,
          labRow = "",
          key.xlab ="Correlation",
          key.title = NA,
          lhei = c(1,4),
          lwid= c(1,3),
          cexCol = 1.2,
          keysize = 1)
legend(coords2, title = "Drug",legend=c("AZ","CP", "DC", "NZ", "PR"), 
       fill=c("#3444DA",  "#DF737A", "#8C5999", "#D7C0D0", "#FFBA49"), cex=0.8, box.lty=0)
# Uncomment if you are saving to file
#ev.off()
```

Now, let's look at *SVD-derived* eigenfeatures (this is the more common way of calculating an eigenfeature).

```{r, message=F, warning = F}
module_clust_svd <- hclust(as.dist(1-cor(t(moduleTraitCor_svd), method="pearson")), method="average")
drug_clust_svd <- hclust(as.dist(1-cor(moduleTraitCor_svd, method="pearson")), method="average")
drug_clust_boot_svd <- pvclust(moduleTraitCor_svd, method.hclust="average",
                           method.dist="correlation", nboot=1000,
                           iseed=2248)


quick_sil <- function(hclust_out, distance, max_k){
  silhouette_score <- function(i){
    k=cutree(hclust_out,i)
    ss <- silhouette(k, 1-cor(distance, method="pearson"))
    mean(ss[, 3])
    }
  clustnum <- 2:max_k
  avg_sil <- sapply(clustnum, silhouette_score)
  avg_sil <- data.frame(num = clustnum, sil_score = avg_sil)
  avg_sil <- rbind(c(1,0), avg_sil)
  return(avg_sil)
}

ms1_svd_sil <- quick_sil(hclust_out=drug_clust_svd, distance = 1-cor(moduleTraitCor_svd, method="pearson"), max_k = 7) 
(ms1_sil <- ggplot(ms1_svd_sil, aes(x=num, y = sil_score)) +
  geom_point(size=4, colour="#F25C54", alpha=1) +
    geom_line(size=2, alpha=0.4) +
    geom_vline(xintercept=2, size = 2, linetype="dashed", color = "#38618C") +
    xlab("Number of clusters") +
    ylab("Average Silhouette Score") +
    scale_x_continuous(breaks = 1:30) +
    theme_classic(base_size=14) +
    ggtitle("MS1")
)

## Visualize the bootstrap clusters
clust_boot_svd <- as.dendrogram(drug_clust_boot_svd)
#pdf(here::here("figs", "ms1_bootstrap_dend.pdf"), width=9, height =4)
drug_clust_boot_svd %>% as.dendrogram() %>% plot(main = "MS1")
drug_clust_boot_svd %>% text 
drug_clust_boot_svd %>% pvrect(alpha=0.9, pv="au")
#dev.off()

## colours for dendrogram branches
clust_cols_ms1_svd <- c("#DF737A", "#3444DA")
## colours for heatmap
new_palette <- colorRampPalette(c("#70A9A1", "white", "#FF9633"))(n=120)

## metadata for clustr heatmap
cor_meta_svd <- data.frame(treatment = colnames(moduleTraitCor_svd)) %>%
    mutate(drug_col = case_when(str_detect(treatment, 'AZ') ~ '#3444DA',
                                str_detect(treatment, 'CP') ~ '#DF737A',
                                str_detect(treatment, 'DC') ~ '#8C5999',
                                str_detect(treatment, 'NZ') ~ '#D7C0D0',
                                str_detect(treatment, 'PR') ~ '#FFBA49'
                                )) %>%
    mutate(conc_col = case_when(str_detect(treatment, '-H') ~ '#08090A',
                                str_detect(treatment, '-M') ~ '#96999C',
                                str_detect(treatment, '-L') ~ '#EAEBEB'))
#range(moduleTraitCor_svd)
# dendrogram for plotting
drug_dend <- color_branches(as.dendrogram(drug_clust_svd), k = 2, col = clust_cols_ms1_svd)


## Uncomment to save PDF of heatmap
#pdf(here::here("figs", "ms1_kmed_hm_svd.pdf"), width=9, height=6)
par(xpd = TRUE) # allows legend to be outside "official" plotting lines
coords2 <- list(x=0, y=0.95)
heatmap.2(moduleTraitCor_svd,
          notecol="black",      # change font color of cell labels to black
          density.info="none",  # turns off density plot inside color legend
          trace="none",         # turns off trace lines inside the heat map
          margins =c(5,0),      # widens margins around plot
          col=new_palette,      # 
          breaks=seq(-0.6,0.6,0.01),    # enable color transition at specified limits
          dendrogram="col",     # only draw a row dendrogram
          Colv=drug_dend,            # turn off column clustering
          Rowv=as.dendrogram(module_clust_svd),
          #ColSideColors = cor_meta$drug_col,
          ColSideColors = cor_meta_svd$drug_col,
          labRow = "",
          key.xlab ="Correlation",
          key.title = NA,
          lhei = c(1,4),
          lwid= c(1,3),
          cexCol = 1.2,
          keysize = 1)
legend(coords2, title = "Drug",legend=c("AZ","CP", "DC", "NZ", "PR"), 
       fill=c("#3444DA",  "#DF737A", "#8C5999", "#D7C0D0", "#FFBA49"), cex=0.8, box.lty=0)
# Uncomment if you are saving to file
#dev.off()
```
Let's save the clustering output so that we can compare to the MS2 results.

```{r}
ms1_moduleTraitCor_pca <- moduleTraitCor_pca
ms1_drugclustboot_pca <- drug_clust_boot_pca
ms1_drugclust_pca <- drug_clust_pca
ms1_moduleTraitCor_svd <- moduleTraitCor_svd
ms1_drugclustboot_svd <- drug_clust_boot_svd
ms1_drugclust_svd <- drug_clust_svd
#4 Uncomment to save the RData file
save(ms1_moduleTraitCor_pca, ms1_drugclust_pca, ms1_drugclustboot_pca,
     ms1_moduleTraitCor_svd, ms1_drugclust_svd, ms1_drugclustboot_svd,
     file=here::here("data", "ms1", "ms1_dedro.RData"))
```
