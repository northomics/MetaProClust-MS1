---
title: "IBD - DeC - MS1-only"
output: html_notebook
---

Loading necessary libraries

```{r, message=F, error=F}
library(renv) #remotes::install_github("rstudio/renv")
#renv::restore()
library(tidyverse)
library(stringr)
library(DESeq2)
library(data.table)
library(dendextend)
library(here)
library(impute)
library(pvclust)
library(gplots)
library(RColorBrewer)
library(cluster)
library(cutr)#devtools::install_github("moodymudskipper/cutr")
library(caret) 
#library(mlbench)
#library(MASS)
#library(glmnet)
#library(foreach)
#library(doParallel)
#registerDoParallel(cores=2)
library(stringr)
library(lubridate)
library(umap)
#library(sva)
#renv::snapshot()
```

## Data input and normalization

Reading MS1 feature intensity data. We will need to subset to only include the consensus features. We'll also organize the samples by "Group" (ie Control, CD, UC)
```{r}    
### For the openMS files
## will have to edit...
## sample info ../data/ms1_openms_sampleinfo.csv
ibd_samples <-  read.csv(here::here("Dataset4-ibd", "data", "ibd-nc-samples.csv"), header=F) %>% 
    dplyr::select(-V1) %>%
    mutate_if(is.character, str_trim)
dc_samples <- read.csv(here::here("Dataset4-ibd", "dc", "dc-samples.csv"), header=F) %>% 
    dplyr::select(-V1) %>%
    mutate_if(is.character, str_trim)
dc_samples <- left_join(dc_samples, ibd_samples, by="V2")
ibd_metadata <- read.csv(here::here("Dataset4-ibd", "data", "ibd-nc-metadata.csv"))
dc_metadata <- left_join(dc_samples, ibd_metadata, by = c("V6" = "Sample.Name")) %>%
    rename(., V2 = "File.Name", V6 = "Sample.Name") %>%
    dplyr::select(-V3.x, -V3.y, -V4, -V5) %>%
    mutate(NewName = paste0(Patient.ID, "_", Diagnosis, "_", Inflammed))




featuresibd <- read.csv(here::here("Dataset4-ibd", "dc", "ibd-nc-dc-ms1features-20mins-50pm.csv"))
consensus_features <- featuresibd %>% dplyr::select(.,contains("cf")) %>% 
    mutate(feat_num = 1:nrow(featuresibd))
ms1 <- featuresibd %>% dplyr::select(.,-contains("cf"))
rt <- ms1 %>% dplyr::select(.,contains("rt"))
mz <- ms1 %>% dplyr::select(.,contains("mz"))
charge <-  ms1 %>% dplyr::select(.,contains("charge"))
intensity <- ms1 %>% dplyr::select(., contains("intensity")) %>% as.data.frame()
colnames(intensity) <- dc_metadata$NewName


intensity_withcf <- data.frame(feature_num = consensus_features$feat_num, RT = consensus_features$rt_cf, MZ = consensus_features$mz_cf, intensity)


ms_order <- read.csv(here::here("Dataset4-ibd", "data", "ms_order.txt"), sep="\t", header=F)
colnames(ms_order) <- c("Month", "Day", "Year", "File")
ms_order$Date <- paste(ms_order$Month, ms_order$Day, ms_order$Year) %>% mdy(.)
ms_order <- ms_order %>% arrange(., Date)
ms_order <- ms_order %>% mutate(basename = str_remove(File, ".raw")) %>%
  mutate(basename = str_remove(basename, "/"))

dc_metadata <- right_join(ms_order, dc_metadata, by=c("basename" = "File.Name")) ## only including samples we used

## Remove samples from 2017

#dc_metadata <- dc_metadata %>% filter(Year != 2017)


## try to reduce number of features...
# reorganize df so that it's in the order of drugs (for filtering)
dc_metadata <- dc_metadata %>% arrange(., Diagnosis)
#intensity_info <- intensity %>% dplyr::select(feature_num, RT,MZ)
intensity <- intensity %>% dplyr::select(dc_metadata$NewName)
#colnames(intensity) <- paste0(colnames(intensity), "_", ibd_meta$Diagnosis) 
intensity <- intensity %>% mutate(feat_num = 1:nrow(intensity))
```

We want to filter the data by missing values and low intensity values. MS1 data is inherently noisy, and so we also filter by low intensity. In this case, we identify intensity quartiles and consider the lowest quartile missing values **only** for the filtering step. We will keep these values for clustering. 


```{r} 
 int <- intensity  %>%  dplyr::select(-feat_num) %>% as.data.frame %>% pivot_longer(names_to = "Name", values_to="intensity", cols=everything()) %>% drop_na()
head(int)
summary(int$intensity)
int_4_quartiles <- smart_cut(int$intensity,4,"groups", labels = c("remove", "Low", "Med", "High"))
table(int_4_quartiles)
int$quart <- int_4_quartiles
max_to_remove <- int %>% filter(quart == "remove")
max_to_remove <- max_to_remove$intensity %>% max()

dens <- density(log2(int$intensity))
df <- data.frame(x=dens$x, y=dens$y)
probs <- c(0,0.25,0.5,0.75,1)
quantiles <- quantile(log2(int$intensity), prob=probs)
df$quant <- factor(findInterval(df$x,quantiles))


(pep_quart_plot <- ggplot(df, aes(x,y)) + geom_line() + 
    geom_ribbon(aes(ymin=0, ymax=y, fill=quant)) + 
    scale_x_continuous(breaks=quantiles) + 
    #scale_fill_brewer(guide="none") +
    xlab("MS1 feature intensities") +
    ylab("Density") +
    scale_fill_viridis_d(option = "plasma", guide = "none") +
    theme_bw() +
    theme(text=element_text(size=14)) 
)




cond_options_all <- table(dc_metadata$Diagnosis) %>% as.data.frame()
cond_opts_all <- cond_options_all$Var1
cond_count_all <- cond_options_all$Freq * 0.5


is.nan.data.frame <- function(x){
    do.call(cbind, lapply(x, is.nan))}
#df = intensity
#conditions = cond_opts
#min_count = cond_count
## add condition to end of all col names...
filter_valids_quart = function(df, conditions, min_count, int_remove, at_least_one = TRUE) {
    df[is.nan.data.frame(df)] <- 0
    df[is.na(df)] <- 0
    df[df <= int_remove] <- 0
    all_names <- colnames(df) 
    cond.names = lapply(conditions, # Group column names by conditions
                        function(x) grep(x, all_names, value = TRUE, perl = TRUE))
    cond.filter = sapply(1:length(cond.names), function(i) {
        df2 = df %>% dplyr::select(cond.names[[i]])   # Extract columns of interest
        df2 = as.matrix(df2)   # Cast as matrix for the following command
        sums = rowSums(df2!=0) # count the number of valid values for each condition
        sums >= min_count[i]   # Calculates whether min_count requirement is met
    })
    if (at_least_one) {
        df$KEEP = apply(cond.filter, 1, any)
    } else {
        df$KEEP = apply(cond.filter, 1, all)
    }
    return(df)  # only keeping rows that meet the criteria!
}

 

## filter by at least Q50 in each treatment considering ZEROS and anything in low quartile
## trying without any quartile adjustment!
ibd_filt <- filter_valids_quart(intensity %>% dplyr::select(-feat_num), 
                               conditions = cond_opts_all,
                               min_count = cond_count_all, 
                               int_remove = max_to_remove,
                               at_least_one = T) #213,383
ibd_filt <- intensity[ibd_filt$KEEP == 1,-59] ## 17,035
filt_feat <- rownames(ibd_filt)


norm_feat<- estimateSizeFactorsForMatrix(ibd_filt)
norm_int <- sweep(ibd_filt, 2, norm_feat, "/") ##peptides are normalized

int <- norm_int %>% as.data.frame %>% pivot_longer(names_to = "Name", values_to="intensity", cols=everything()) %>% drop_na()
head(int)
summary(int$intensity)
int_4_quartiles <- smart_cut(int$intensity,4,"groups", labels = c("remove", "Low", "Med", "High"))
table(int_4_quartiles)
int$quart <- int_4_quartiles
#max_to_remove <- int %>% filter(quart == "remove")
#max_to_remove <- max_to_remove$intensity %>% max()

dens <- density(log2(int$intensity))
df <- data.frame(x=dens$x, y=dens$y)
probs <- c(0,0.25,0.5,0.75,1)
quantiles <- quantile(log2(int$intensity), prob=probs)
df$quant <- factor(findInterval(df$x,quantiles))


(pep_quart_plot <- ggplot(df, aes(x,y)) + geom_line() + 
    geom_ribbon(aes(ymin=0, ymax=y, fill=quant)) + 
    scale_x_continuous(breaks=quantiles) + 
    #scale_fill_brewer(guide="none") +
    xlab("MS1 feature intensities") +
    ylab("Density") +
    scale_fill_viridis_d(option = "plasma", guide = "none") +
    theme_bw() +
    theme(text=element_text(size=14)) 
)

```

## Missing data imputation

Although we filtered data, we are still left with missing values that will cause challenges with log transformation and fold change calculations. We used a KNN data imputation.

```{r, message=F, warning=F}
## impute missing values
#intensity_0 <- intensity %>%  mutate_all(~replace(., is.nan(.), 0))

imputed_feat <- impute.knn(norm_int %>% as.matrix(), k = 10, rowmax = 0.5, colmax = 0.95, rng.seed = 362436069)
```

## Batch effect?

The IBD samples were run on the MS/MS years apart. This means we may expect some sort of batch effect to emerge. There were no specific "batches", but we will probably need to adjust for some differences due to time of year, changes in columns, etc.

Let's use UMAP on the unfiltered and un-normalized data to see if we can find any clusters that we would not expect.


```{r}
imputed_noZero <- imputed_feat$data
imputed_noZero[imputed_noZero  == 0] <- 0.0001

log_exp <- data.frame(imputed_noZero) %>%
    mutate_all(., funs(log2(.)))
colnames(log_exp) = colnames(imputed_feat$data)
ms1_umap <- umap(log_exp %>% as.matrix %>% t(), n_components=2, random_state=2248)
#ibd_meta <- ibd_meta[match(colnames(log_exp), ibd_meta$NewName),]
coords_umap<-data.frame(ms1_umap$layout, Diagnosis = dc_metadata$Diagnosis,
                   #samplename = colnames(log_exp_DC),
                   Sex = dc_metadata$Gender,
                   #Site = dc_metadata$Location,
                   Inflammation = dc_metadata$Inflammed, Date=dc_metadata$Date)
coords_umap$Diagnosis <- factor(coords_umap$Diagnosis, levels = c("Control", "UC", "CD"))
coords_umap$Inflammation <- factor(coords_umap$Inflammation, levels = c("Yes","No"))
labels <- pretty(coords_umap$Date, 5)
(umap_plot_diagnosis <- ggplot(coords_umap, aes(x = X1, y = X2)) +
        geom_point(size=5, aes(shape = Inflammation, color = Diagnosis)) + 
        scale_color_manual(values=c("#8FBFE0", "#F57251",  "#3444DA"))+
        #scale_color_gradient(
  #  low="yellow", high="purple", 
  #  breaks = as.integer(labels), 
  #  labels = format(labels, "%m/%d/%y")
 # ) +
        scale_x_continuous(name="UMAP1") + 
        scale_y_continuous(name="UMAP2") +
        theme_bw() +
        theme(legend.position = "right", text=element_text(size=16)))

(umap_plot_date <- ggplot(coords_umap, aes(x = X1, y = X2)) +
        geom_point(size=5, aes(shape = Diagnosis, color = Date)) + 
        #scale_color_manual(values=c("#3444DA",  "#DF737A", "#8C5999", "#00916E", "#D7C0D0", "#FFBA49")) +
        scale_color_gradient(
    low="yellow", high="purple", 
    breaks = as.integer(labels), 
    labels = format(labels, "%m/%d/%y")
  ) +
        scale_x_continuous(name="UMAP1") + 
        scale_y_continuous(name="UMAP2") +
        theme_bw() +
        theme(legend.position = "right", text=element_text(size=16)))
# ggsave(filename = "../../../4.mSystems/2.revisionv2/figs/umap-dc-diagnosis.pdf", umap_plot_diagnosis, width = 8, height = 6, units = "in")
# ggsave(filename = "../../../4.mSystems/2.revisionv2/figs/umap-dc-diagnosis.eps", umap_plot_diagnosis, width = 8, height = 6, units = "in")
# ggsave(filename = "../../../4.mSystems/2.revisionv2/figs/umap-dc-date.pdf", umap_plot_date, width = 8, height = 6, units = "in")
# iggsave(filename = "../../../4.mSystems/2.revisionv2/figs/umap-dc-date.eps", umap_plot_date, width = 8, height = 6, units = "in")
# write.csv(log_exp, here::here("Dataset4-ibd","dc", "dataset4-dc-ms1_log2_normalized.csv"), quote=F, row.names = T)
```
## Log2 intensity transformation and PCA quality check

We then should log transform the intensity values and perform a PCA for a QC check.




```{r, message=F, warning=F}
## easy and quick PCA function for manual colour and shape
quick_pca <- function(coords_df, x_PC, y_PC, PoV, shape, fill){
    yaxis <- y_PC
    xaxis <- x_PC
    yperc <- paste0("(", round(PoV[yaxis %>% as.numeric()] ,2), "%)")
    xperc <- paste0("(", round(PoV[xaxis %>% as.numeric()] ,2), "%)")
    yaxislabel <- paste0("PC", yaxis, " ", yperc)
    xaxislabel <- paste0("PC", xaxis, " ", xperc)
    pca_plot <- ggplot(coords_df, aes_string(x = paste0('PC', xaxis), y = paste0('PC', yaxis))) +
        geom_point(size=4, aes_string(shape = shape, color = fill)) + 
        scale_color_manual(values=c("#3444DA",  "#DF737A", "#8C5999", "#00916E", "#D7C0D0", "#FFBA49")) +
        scale_x_continuous(name=xaxislabel) + 
        scale_y_continuous(name=yaxislabel) +
        theme_bw() +
        theme(legend.position = "right", text=element_text(size=16))
    return(pca_plot)
}

## easy and quick PCA funcDCon for manual colour and shape
quick_pca_date <- function(coords_df, x_PC, y_PC, PoV, shape, fill){
    yaxis <- y_PC
    xaxis <- x_PC
    yperc <- paste0("(", round(PoV[yaxis %>% as.numeric()] ,2), "%)")
    xperc <- paste0("(", round(PoV[xaxis %>% as.numeric()] ,2), "%)")
    yaxislabel <- paste0("PC", yaxis, " ", yperc)
    xaxislabel <- paste0("PC", xaxis, " ", xperc)
    pca_plot <- ggplot(coords_df, aes_string(x = paste0('PC', xaxis), y = paste0('PC', yaxis))) +
        geom_point(size=4, aes_string(shape = shape, color = fill)) + 
        #scale_color_manual(values=c("#3444DA",  "#DF737A", "#8C5999", "#00916E", "#D7C0D0", "#FFBA49")) +
  scale_color_gradient(
    low="yellow", high="purple", 
    breaks = as.integer(labels), 
    labels = format(labels, "%m/%d/%y")
  ) +
      scale_x_continuous(name=xaxislabel) + 
        scale_y_continuous(name=yaxislabel) +
        theme_bw() +
        theme(legend.position = "right", text=element_text(size=16))
    return(pca_plot)
}


#log_exp <- data.frame(imputed_feat$data) %>%
#    mutate_all(., funs(log2(1 + .)))
#colnames(log_exp) = colnames(imputed_feat$data)
pca_all<- prcomp(log_exp %>% t(), center=T, scale=F)
sampleVals<-data.frame(pca_all$x)
exprVals<-data.frame(pca_all$rotation)
PoV <- (pca_all$sdev^2/sum(pca_all$sdev^2))*100 

coords<-data.frame(sampleVals, Diagnosis = dc_metadata$Diagnosis,
                   samplename = rownames(sampleVals),
                   Sex = dc_metadata$Gender,
                   #Site =  dc_metadata$Location,
                   Inflammed =  dc_metadata$Inflammed, Date= dc_metadata$Date) #,
                   #Age = ibd_meta$Age)
coords$Diagnosis <- factor(coords$Diagnosis, levels = c("Control", "UC", "CD"))
numPCs_all <- 1:length(PoV)

for (i in 1:length(PoV)) {
    percent <- paste0("(", round(PoV[i],2), "%)")
    name <- paste0("PC", i, "per")
    assign(name, percent)
}
(pc12 <- quick_pca(coords_df = coords, x_PC = 2, y_PC = 1, PoV = PoV, shape = "Inflammed", fill = "Diagnosis"))

(pc12_all <- quick_pca_date(coords_df = coords, x_PC = 2, y_PC = 1, PoV = PoV, shape = "Diagnosis", fill = "Date"))

(pc23_all <- quick_pca(coords_df = coords, x_PC = 2, y_PC = 3, PoV = PoV, shape = "Inflammed", fill = "Diagnosis"))

(pc23_all <- quick_pca_date(coords_df = coords, x_PC = 2, y_PC = 3, PoV = PoV, shape = "Diagnosis", fill = "Date"))
```

## Cluster eigenfeature calculation and clustering visualization

After we use `Python` for clustering our relatively large dataset, let's calculate summary statistics of each peptide cluster considering the peptide intensity values. We will calculate eigenfactors two ways and compare the two results.


```{r message=F, warning=F}


kmedoid_labels <- read.csv(here::here("Dataset4-ibd", "dc", "k-med_labels.csv"), header=F) %>% as.vector()

clusterinfopep <- kmedoid_labels %>% data.frame()

max_clust <- kmedoid_labels %>% unique() %>% max()
print(paste("Number of clusters:", max_clust+1))
clusters <- list()

## creating a list that contains intensities of each peptide cluster
for (x in 0:max_clust){
    clustername <- paste("Cluster", x)
    y <- kmedoid_labels[which(kmedoid_labels$V1 == x),,drop=F] %>% rownames()
    intensities <- log_exp[y %>% as.numeric(),] %>% as.data.frame()
    intensities <- intensities %>% mutate(feat_num = y)
    clusters[[clustername]] <- intensities
}

### eigenfactors
### Singular value decomposition for genome-wide expression data processing and modeling
###  https://doi.org/10.1073/pnas.97.18.10101
## https://www.biostars.org/p/299167/
## eigengenes <- svd(X)$v


svd_clusters <- lapply(clusters, function(x) svd(x %>% dplyr::select(-feat_num))$v)
# grabbing the first principal component
svd1_cluster <- lapply(svd_clusters,  "[", , 1)


clustereigenfactors_svd <- bind_cols(svd1_cluster) %>% data.frame()
```

Complete the correlation with groups and inflammation. 

```{r message=F, warning=F}
## make a factored dataframe of the compounds

dc_metadata <- dc_metadata %>% mutate(diag_inflam = paste0(Diagnosis, "_", Inflammed))

datTraits <- data.frame(diag_inflam =  as.factor(dc_metadata$diag_inflam))
rownames(datTraits) <- dc_metadata$NewName
traits <- model.matrix(~ ., data=datTraits,
                       contrasts.arg = lapply(datTraits, contrasts, contrasts=FALSE))
traits <- traits[,-1] ##removing intercept
#moduleTraitCor_pca <- stats::cor(clustereigenfactors_pca, traits, method = "s")
moduleTraitCor_svd <- stats::cor(clustereigenfactors_svd, traits, method = "s")
#colnames(moduleTraitCor_pca) <- colnames(moduleTraitCor_pca) %>% substr(., 10, nchar(colnames(moduleTraitCor_pca)))
colnames(moduleTraitCor_svd) <- colnames(moduleTraitCor_svd) %>% substr(., 12, nchar(colnames(moduleTraitCor_svd)))
```

Now, let's look at *SVD-derived* eigenfeatures (this is the more common way of calculating an eigenfeature).

```{r, message=F, warning = F}
module_clust_svd <- hclust(as.dist(1-cor(t(moduleTraitCor_svd), method="pearson")), method="average")
drug_clust_svd <- hclust(as.dist(1-cor(moduleTraitCor_svd, method="pearson")), method="average")
drug_clust_boot_svd <- pvclust(moduleTraitCor_svd, method.hclust="average",
                           method.dist="correlation", nboot=1000,
                           iseed=2248)


quick_sil <- function(hclust_out, distance, max_k){
  silhouette_score <- function(i){
    k=cutree(hclust_out,i)
    ss <- silhouette(k, 1-cor(distance, method="pearson"))
    mean(ss[, 3])
    }
  clustnum <- 2:max_k
  avg_sil <- sapply(clustnum, silhouette_score)
  avg_sil <- data.frame(num = clustnum, sil_score = avg_sil)
  avg_sil <- rbind(c(1,0), avg_sil)
  return(avg_sil)
}
#
ms1_svd_sil <- quick_sil(hclust_out=drug_clust_svd, distance = 1-cor(moduleTraitCor_svd, method="pearson"), max_k = 4) 
(ms1_sil <- ggplot(ms1_svd_sil, aes(x=num, y = sil_score)) +
  geom_point(size=4, colour="#F25C54", alpha=1) +
    geom_line(size=2, alpha=0.4) +
    geom_vline(xintercept=3, size = 2, linetype="dashed", color = "#38618C") +
    xlab("Number of clusters") +
    ylab("Average Silhouette Score") +
    scale_x_continuous(breaks = 1:30) +
    theme_classic(base_size=14) +
    ggtitle("DC-IBD MS1-only clusters")
)

## Visualize the bootstrap clusters
clust_boot_svd <- as.dendrogram(drug_clust_boot_svd)
#pdf(here::here("figs", "ms1_bootstrap_dend.pdf"), width=9, height =4)
drug_clust_boot_svd %>% as.dendrogram() %>% plot(main = "MS1")
drug_clust_boot_svd %>% text 
drug_clust_boot_svd %>% pvrect(alpha=0.9, pv="au")
#dev.off()

## colours for dendrogram branches
clust_cols_ms1_svd <- c("#48392A", "#48392A")

dc_ibd_dend <- color_branches(as.dendrogram(drug_clust_svd), k = 3, col = clust_cols_ms1_svd) %>%
    dendextend::set("branches_lwd", 2)

k_3 <- cutree(dc_ibd_dend, k = 3, order_clusters_as_data = FALSE) 
dc_ibd_dend <- branches_attr_by_clusters(
  dc_ibd_dend,
  clusters = k_3,
  values = c(1,2,3),
  attr =  "lty"
)
## metadata for clustr heatmap
#"#1446A0",  "#DB3069", "#FFBA08
cor_meta_svd <- data.frame(Sample = labels(dc_ibd_dend)) %>%
    mutate(overall = case_when(str_detect(Sample, 'CD_Yes') ~ '#1446A0',
                                str_detect(Sample, 'UC_Yes') ~ '#DB3069',
                                str_detect(Sample, 'UC_No') ~ '#FFBA08',
                                str_detect(Sample, "CD_No") ~ '#5AAA95',
                               str_detect(Sample, "Control_No") ~ "grey"),
    Diagnosis = case_when(str_detect(Sample, 'UC') ~ '#F57251',
                          str_detect(Sample, 'CD') ~ '#3444DA',
                          str_detect(Sample, 'Control') ~ '#8FBFE0'),
    Inflammation = case_when(str_detect(Sample, 'Yes') ~ '#131112',
                          str_detect(Sample, 'No') ~ '#F7F7FF'))


dc_ibd_dend <- dc_ibd_dend %>% set_labels(., labels = c("Control", "UC", "CD (infl.)", "CD", "UC (infl.)"))
                                            
#pdf(here::here("Dataset4-ibd", "dc", "ibd-dc-dend.pdf"))
dc_ibd_dend %>% plot()
colored_bars(colors = cor_meta_svd %>% dplyr::select(-Sample, -overall), dend = dc_ibd_dend, sort_by_labels_order = FALSE)
#dev.off()
```




```{r}

## colours for heatmap
#new_palette <- colorRampPalette(c("#70A9A1", "white", "#FF9633"))(n=160)
#
### Uncomment to save PDF of heatmap
##pdf(here::here("ibd","figs", "ibd-ms1_heatmap.pdf"), width=9, height=6)
#par(xpd = TRUE) # allows legend to be outside "official" plotting lines
#coords2 <- list(x=0, y=0.95)
#heatmap.2(moduleTraitCor_svd,
#          notecol="black",      # change font color of cell labels to black
#          density.info="none",  # turns off density plot inside color legend
#          trace="none",         # turns off trace lines inside the heat map
#          margins =c(5,0),      # widens margins around plot
#          col=new_palette,      # 
#          breaks=seq(-0.8,0.8,0.01),    # enable color transition at specified limits
#          dendrogram="col",     # only draw a row dendrogram
#          Colv=drug_dend,            # turn off column clustering
#          Rowv=as.dendrogram(module_clust_svd),
#          #ColSideColors = cor_meta$drug_col,
#          ColSideColors = cor_meta_svd$drug_col,
#          labRow = "",
#          key.xlab ="Pearson Correlation Coefficient",
#          key.title = NA,
#          lhei = c(1,4),
#          lwid= c(1,3),
#          cexCol = 1.2,
#          keysize = 1)
#legend(coords2, title = "Groups",legend=c("CD-A", "UC-A", "UC-N"), 
#       fill=c("#1446A0",  "#DB3069", "#FFBA08"), cex=0.8, box.lty=0)
# Uncomment if you are saving to file
#dev.off()
```